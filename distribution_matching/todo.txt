1.- No se si sería más facil tomar r=uniforme, y no r=mixture model, simplifica mucho el sampling y tal vez incluso produzca menos error
2.- Por ahora tengo KLD y HD:
    - para KLD no he entendido si tengo que añadir el -x + y
3.- Se puede poner la topsoe como una f-divergence?
    La topsoe parece que es 2 veces la jensen-shannon divergence, o sea
    topsoe(p,q) = kld(p|m) + kld(q|m), con m = (p+q)/2
4.- Se puede poner la Wasserstein como una f-divergence?
5.- En general, qué relación hay con las "distancias"?


2) implementar el auto
    - optimización interna para likelihood [ninguno parece funcionar bien]
        - de todo (e.g., todo el training)?
        - independiente para cada conjunto etiquetado? (e.g., positivos, negativos, neutros, y test)
    - optimización como un parámetro GridSearchQ
6) optimizar kernel? optimizar distancia?
10) Definir un clasificador que devuelva, para cada clase, una posterior como la likelihood en la class-conditional KDE dividida
    por la likelihood en en todas las clases (como propone Juanjo) y meterlo en EMD. Hacer al contario: re-calibrar con
    EMD y meterlo en KDEy
11) KDEx?

